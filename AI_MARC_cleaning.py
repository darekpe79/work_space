# -*- coding: utf-8 -*-
import pandas as pd
import json
from tqdm import tqdm 
csv_file = "C:/Users/darek/Downloads/500 a.csv"  # ÅšcieÅ¼ka do pliku

# Wczytanie pliku i ustawienie nowych nagÅ‚Ã³wkÃ³w
df = pd.read_csv(csv_file, encoding="utf-8", on_bad_lines="skip", quotechar='"', header=0, names=["id", "field500"])
df_filtered = df[df["field500"].astype(str).str.startswith("TytuÅ‚ oryginaÅ‚u:")]
# WyÅ›wietlenie danych
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline

# Nazwa modelu
# model_name = "CYFRAGOVPL/Llama-PLLuM-8B-instruct"
# model_name ="CYFRAGOVPL/PLLuM-12B-nc-instruct"

# # Konfiguracja kwantyzacji
# quant_config = BitsAndBytesConfig(
#     load_in_8bit=True,                         # WÅ‚Ä…cz kwantyzacjÄ™ 8-bitowÄ…
#     llm_int8_enable_fp32_cpu_offload=True      # Offload czÄ™Å›ci modelu na CPU
# )

# # Wczytanie tokenizera
# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# # Wczytanie modelu z konfiguracjÄ… kwantyzacji
# model = AutoModelForCausalLM.from_pretrained(
#     model_name,
#     device_map="auto",                         # Automatyczne przypisanie GPU/CPU
#     quantization_config=quant_config,         # Nowa metoda dla 8-bit
#     trust_remote_code=True
# )


# kweantyzacja 4bit proby

model_name = "CYFRAGOVPL/PLLuM-12B-nc-instruct"

# Konfiguracja dla 4-bitowej kwantyzacji
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,                     # WÅ‚Ä…cz kwantyzacjÄ™ 4-bitowÄ…
    bnb_4bit_compute_dtype="float16",      # Precyzja obliczeÅ„ (float16 dziaÅ‚a dobrze na wiÄ™kszoÅ›ci GPU)
    bnb_4bit_quant_type="nf4",             # UÅ¼yj Normalized Float 4 (NF4) - lepsza jakoÅ›Ä‡
    llm_int8_enable_fp32_cpu_offload=True  # Offload czÄ™Å›ci obliczeÅ„ na CPU
)

# ZaÅ‚aduj model z kwantyzacjÄ…
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quant_config,
    device_map="auto"  # Automatyczny przydziaÅ‚ GPU/CPU
)

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)
model.eval()
# Pipeline do generowania tekstu
generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    return_full_text=False
)

# Funkcja do zadawania pytaÅ„
# def ask_llama_pllum(prompt: str, max_new_tokens=1000) -> str:
#     output = generator(
#         prompt,
#         max_new_tokens=max_new_tokens,
#         do_sample=True,
#         temperature=0.7,
#         top_p=0.8,
#         repetition_penalty=1.2
#     )
#     return output[0]["generated_text"]
import torch 

# Ustaw ziarno dla caÅ‚ego skryptu
torch.manual_seed(42)

torch.backends.cudnn.deterministic = True  # ZwiÄ™ksza determinizm
torch.backends.cudnn.benchmark = False     # WyÅ‚Ä…cza optymalizacje, ktÃ³re mogÄ… wprowadzaÄ‡ losowoÅ›Ä‡


# 2. Zmodyfikowana funkcja generowania
def ask_llama_pllum(prompt: str, max_new_tokens=1000) -> str:
    output = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.5,
        top_p=0.7,
        repetition_penalty=1.2
    )
    return output[0]["generated_text"]




# 2. Dopiero potem tworzysz f-string, ktÃ³ry z niej korzysta:
# 1. Szablon promptu
interpret_prompt = """JesteÅ› specjalistÄ… bibliografem. Chcesz wydobyÄ‡ tytuÅ‚y oryginalnych utworÃ³w z pola 500a w formacie MARC21. 
TytuÅ‚y zwykle zaczynajÄ… siÄ™ od sÅ‚Ã³w "TytuÅ‚ oryginaÅ‚u:", a nastÄ™pnie moÅ¼e wystÄ™powaÄ‡ sam tytuÅ‚, numer woluminu lub tytuÅ‚ cyklu.

Oto przykÅ‚ady:
- "TytuÅ‚ oryginaÅ‚u: La disparition. Rok wydania na podstawie strony internetowej wydawcy." 
  â†’ wydobywasz "La disparition." (bez roku)
- "TytuÅ‚ oryginaÅ‚u: The winds of Dune. Stanowi kontynuacjÄ™ sagi Kroniki Diuny Franka Herberta."
  â†’ wydobywasz "The winds of Dune."
- "TytuÅ‚ oryginaÅ‚u: Noir burlesque. 2"
  â†’ wydobywasz "Noir burlesque. 2"
- "TytuÅ‚ oryginaÅ‚u: Bloody Mary. 3. Numeracja stron od prawej do lewej."
  â†’ wydobywasz "Bloody Mary. 3."
- "TytuÅ‚ oryginaÅ‚u: D.O.G.S. Kontynuacja powieÅ›ci pt:. S.T.A.G.S."
  â†’ wydobywasz "D.O.G.S."
- "TytuÅ‚ oryginaÅ‚u: Memoria, 2023. TytuÅ‚ oryginaÅ‚u cyklu: En Rekke/Vargas deckare."
  â†’ wydobywasz "Memoria" w kluczu "title", "2023" w kluczu "year", a "En Rekke/Vargas deckare" w kluczu "series_title" â€“ nie powtarzaj tego w "title"!

**Format odpowiedzi** musi byÄ‡ wyÅ‚Ä…cznie!!! w postaci JSON, na przykÅ‚ad:

{{
  "title": ["A prison diary.", "Vol. 1, Belmarsh: hell", "Vol. 2, Wayland: purgatory", "Vol. 3, North Sea Camp: heaven"],
  "year": "1991",
  "series_title": "The vampire diaries"
}}

### Zasady:
1. **Zawsze zwrÃ³Ä‡ klucz `"title"`** â€“ nawet jeÅ›li tytuÅ‚Ã³w nie da siÄ™ ustaliÄ‡, zwrÃ³Ä‡ `"title": []`.
2. JeÅ›li wystÄ™puje `"TytuÅ‚ oryginaÅ‚u cyklu:"`, zapisz wartoÅ›Ä‡ w `"series_title"`, **nie** umieszczaj tego w `"title"`.
3. JeÅ›li w tekÅ›cie pojawia siÄ™ rok (np. po tytule, "Memoria, 2023."), zapisz go w `"year"` â€“ ale **nie** w kluczu `"title"`.
4. Nigdy nie zwracaj `null`. JeÅ›li jakaÅ› informacja nie wystÄ™puje w tekÅ›cie, **pomijaj** ten klucz.
5. Nie dodawaj Å¼adnych innych informacji czy wyjaÅ›nieÅ„ â€“ **ma byÄ‡ samo JSON**.
6. JeÅ›li masz "TytuÅ‚ oryginaÅ‚u:" i coÅ› dalej, zawsze to wydobÄ…dÅº (z pominiÄ™ciem sÅ‚owa "TytuÅ‚ oryginaÅ‚u:").
7. **Nie** twÃ³rz osobnych kluczy dla sÅ‚Ã³w typu "Kontynuacja powieÅ›ci" czy "Rok wydania" â€“ te informacje ignoruj, jeÅ›li nie wnoszÄ… nowych tytuÅ‚Ã³w.

Teraz zadanie dla Ciebie: Skup siÄ™ tylko na tym â€“ nie wracaj do przykÅ‚adÃ³w.  
PoniÅ¼ej masz treÅ›Ä‡, na podstawie ktÃ³rej masz wygenerowaÄ‡ odpowiedÅº:

{user_question}

OdpowiedÅº:

"""
interpret_prompt = """JesteÅ› specjalistÄ… bibliografem. Chcesz wydobyÄ‡ tytuÅ‚y oryginalnych utworÃ³w z pola 500a w formacie MARC21. 
TytuÅ‚y zwykle zaczynajÄ… siÄ™ od sÅ‚Ã³w "TytuÅ‚ oryginaÅ‚u:", a nastÄ™pnie moÅ¼e wystÄ™powaÄ‡ sam tytuÅ‚, numer woluminu lub tytuÅ‚ cyklu.

Oto przykÅ‚ady:
- "TytuÅ‚ oryginaÅ‚u: La disparition. Rok wydania na podstawie strony internetowej wydawcy." 
  â†’ wydobywasz "La disparition." (bez roku)
- "TytuÅ‚ oryginaÅ‚u: The winds of Dune. Stanowi kontynuacjÄ™ sagi Kroniki Diuny Franka Herberta."
  â†’ wydobywasz "The winds of Dune."
- "TytuÅ‚ oryginaÅ‚u: Noir burlesque. 2"
  â†’ wydobywasz "Noir burlesque. 2"
- "TytuÅ‚ oryginaÅ‚u: Bloody Mary. 3. Numeracja stron od prawej do lewej."
  â†’ wydobywasz "Bloody Mary. 3."
- "TytuÅ‚ oryginaÅ‚u: D.O.G.S. Kontynuacja powieÅ›ci pt:. S.T.A.G.S."
  â†’ wydobywasz "D.O.G.S."
- "TytuÅ‚ oryginaÅ‚u: Memoria, 2023. TytuÅ‚ oryginaÅ‚u cyklu: En Rekke/Vargas deckare."
  â†’ wydobywasz "Memoria" w kluczu "title", "2023" w kluczu "year", a "En Rekke/Vargas deckare" w kluczu "series_title" â€“ nie powtarzaj tego w "title"!
- "TytuÅ‚ oryginaÅ‚u: The temporary bride : a memoir of love and food in Iran."
  â†’ wydobywasz "The temporary bride : a memoir of love and food in Iran."
**Format odpowiedzi** musi byÄ‡ wyÅ‚Ä…cznie w postaci JSON, na przykÅ‚ad:

{{
  "title": ["A prison diary.", "Vol. 1, Belmarsh: hell", "Vol. 2, Wayland: purgatory", "Vol. 3, North Sea Camp: heaven"],
  "year": "1991",
  "series_title": "The vampire diaries"
}}


### Zasady:
1. **Zawsze zwrÃ³Ä‡ klucz `"title"`** â€“ nawet jeÅ›li tytuÅ‚Ã³w nie da siÄ™ ustaliÄ‡, zwrÃ³Ä‡ `"title": []`.
2. JeÅ›li wystÄ™puje `"TytuÅ‚ oryginaÅ‚u cyklu:"`, zapisz wartoÅ›Ä‡ w `"series_title"`, **nie** umieszczaj tego w `"title"`.
3. JeÅ›li w tekÅ›cie pojawia siÄ™ rok (np. po tytule, "Memoria, 2023."), zapisz go w `"year"` â€“ ale **nie** w kluczu `"title"`.
4. Nigdy nie zwracaj `null`. JeÅ›li jakaÅ› informacja nie wystÄ™puje w tekÅ›cie, **pomijaj** ten klucz.
5. **ZwrÃ³Ä‡ tylko JSON** â€“ nie dodawaj Å¼adnych innych informacji czy wyjaÅ›nieÅ„.
6. JeÅ›li masz "TytuÅ‚ oryginaÅ‚u:" i coÅ› dalej, zawsze to wydobÄ…dÅº (z pominiÄ™ciem sÅ‚owa "TytuÅ‚ oryginaÅ‚u:").
7. **Nie!!!!! twÃ³rz osobnych kluczy dla sÅ‚Ã³w typu "Kontynuacja powieÅ›ci" czy "Rok wydania" â€“ te informacje ignoruj, jeÅ›li nie wnoszÄ… nowych tytuÅ‚Ã³w.
8. Nie dodawaj pÃ³l od siebie!!! UÅ¼ywaj tylko tych, ktÃ³re wskazaÅ‚em, jeli znajdujesz takie informacje!!!

Teraz zadanie dla Ciebie: Skup siÄ™ tylko na tym â€“ nie wracaj do przykÅ‚adÃ³w uÅ¼ywaj tylko pÃ³l na jakie siÄ™ umÃ³wilismy title, year series title i upewnij siÄ™, Å¼e wydobywasz caÅ‚oÄ‡ tytuÅ‚u, czasem po dwukropku, czy innym znaku interpunkcyjnym jest druga czÄ™sÄ‡, choÄ‡ na to nie wyglÄ…da!!.  
PoniÅ¼ej masz treÅ›Ä‡, na podstawie ktÃ³rej masz wygenerowaÄ‡ odpowiedÅº:

{user_question}

OdpowiedÅº:

"""

# 2. PrzykÅ‚adowy "user_question
user_query =  "TytuÅ‚ oryginaÅ‚u: The temporary bride : a memoir of love and food in Iran."

# 3. Wstawianie treÅ›ci do promptu
interp = interpret_prompt.format(user_question=user_query)
interpretation = ask_llama_pllum(interp, max_new_tokens=500)
# 4. SprawdÅº efekt
print(interpretation)

df_small = df_filtered.head(100)

results = []

for idx, row in tqdm(df_filtered.iterrows(), total=len(df_filtered), desc="Przetwarzanie rekordÃ³w"):
    # 4a. Wstawiamy aktualny 'field500' do promptu
    user_query = row["field500"]
    print(user_query)
    interp = interpret_prompt.format(user_question=user_query)

    # 4b. WywoÅ‚ujemy model
    interpretation = ask_llama_pllum(interp, max_new_tokens=500)
    
    # 4c. Dodajemy do listy wynikÃ³w np. w formacie:
    # {"id": 123, "interpretation": {...}}
    results.append({
        "id": row["id"],
        "field 500": user_query, 
        "interpretation": interpretation
    })

df_results = pd.DataFrame(results)

# 1. Zapis do JSON
for item in results:
    interpretation_str = item.get("interpretation", "")
    print(interpretation_str)
    if interpretation_str:
        try:
            # Zamiana surowego tekstu JSON w Pythonowy sÅ‚ownik
            item["interpretation"] = json.loads(interpretation_str)
        except json.JSONDecodeError:
            # JeÅ›li Å‚aÅ„cuch jest nieprawidÅ‚owy, moÅ¼na ustawiÄ‡ None lub inny fallback
            item["interpretation"] = None

json_output_file = "C:/Users/darek/Downloads/interpretation_results_fixed_small_gmodel2.json"
with open(json_output_file, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=4)

print(f"Zapisano wyniki w formacie JSON do: {json_output_file}")

# 2. Zapis do Excela
excel_output_file = "C:/Users/darek/Downloads/interpretation_results.xlsx"
df_results.to_excel(excel_output_file, index=False)

print(f"Zapisano wyniki do pliku {json_output_file} i {excel_output_file}")




#%% DEEP seek

from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
model="deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
quant_config = BitsAndBytesConfig(
    load_in_4bit=True,                     # Aktywuj kwantyzacjÄ™ 4-bitowÄ…
    bnb_4bit_compute_dtype="float16",      # Ustawienia obliczeniowe
    bnb_4bit_quant_type="nf4",             # UÅ¼ycie Normalized Float 4 (NF4) dla lepszej jakoÅ›ci
    llm_int8_enable_fp32_cpu_offload=True  # Offload obliczeÅ„ na CPU w razie potrzeby
)

model = AutoModelForCausalLM.from_pretrained(
    model,
    quantization_config=quant_config,
    device_map="auto"
)

tokenizer = AutoTokenizer.from_pretrained(model)

generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    return_full_text=False  # Nie powtarzaj promptu w generowanej odpowiedzi
)

# ğŸ”¹ Funkcja do zadawania pojedynczych pytaÅ„ (bez przechowywania historii)
def ask_model(prompt: str, max_new_tokens=150) -> str:
    output = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.6,   # Niska temperatura dla bardziej przewidywalnych odpowiedzi
        top_p=0.7,
        repetition_penalty=1.2
    )
    
    # Pobranie czystego tekstu odpowiedzi
    response = output[0]["generated_text"].strip()
    
    return response

def ask_model(prompt: str, max_new_tokens=1000) -> str:
    output = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.5,
        top_p=0.7,
        repetition_penalty=1.2
    )
    return output[0]["generated_text"]


interpretation = ask_model(" give me capitals of europe", max_new_tokens=500)



interpret_prompt = """JesteÅ› specjalistÄ… bibliografem. WydobÄ…dÅº tytuÅ‚y oryginalnych utworÃ³w z pola 500a MARC21. 

TytuÅ‚y zaczynajÄ… siÄ™ od "TytuÅ‚ oryginaÅ‚u:". MogÄ… zawieraÄ‡ numer tomu lub tytuÅ‚ serii.

### **Zasady:**
- `"title"` â†’ wszystkie tytuÅ‚y.
- `"series_title"` â†’ jeÅ›li jest `"TytuÅ‚ oryginaÅ‚u cyklu:"`.
- `"year"` â†’ jeÅ›li po tytule znajduje siÄ™ rok.
- **Nie dodawaj niczego od siebie!** JeÅ›li brak informacji, **pomijaj klucz**.

Teraz wydobÄ…dÅº informacje z podanego tekstu i zwrÃ³Ä‡ wynik w formacie JSON:

{user_question}

OdpowiedÅº:
"""


# 2. PrzykÅ‚adowy "user_question
user_query =  "TytuÅ‚ oryginaÅ‚u: The temporary bride : a memoir of love and food in Iran."

# 3. Wstawianie treÅ›ci do promptu
interp = interpret_prompt.format(user_question=user_query)
interpretation = ask_model(interp, max_new_tokens=500)
# 4. SprawdÅº efekt
print(interpretation)

import torch
print("PyTorch version:", torch.__version__)
print("CUDA version:", torch.version.cuda)

